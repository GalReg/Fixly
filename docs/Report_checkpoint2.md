# Чекпоинт 2: Core (RAG / Агент / LLM Chain)

## 1. Описание архитектуры пайплайна

### Общая архитектура системы

Проект Fixly представляет собой AI-ассистента для диагностики бытовой техники, построенного на основе RAG-архитектуры (Retrieval-Augmented Generation). Система состоит из нескольких ключевых компонентов, которые работают в связке для обеспечения качественной диагностики.

### Основные компоненты

**1. Векторная база данных (FAISS)**

База данных содержит ~108 000 текстовых чанков, извлеченных из 54 376 руководств по ремонту iFixit. Каждый чанк представляет собой фрагмент текста размером 2000 символов с перекрытием в 400 символов. Для векторизации используется модель YandexGPTEmbeddings, которая преобразует текстовые фрагменты в векторные представления для эффективного семантического поиска.

**2. Retriever (поисковый модуль)**

Модуль реализует семантический поиск по векторной базе данных. При получении запроса пользователя система извлекает k=3 наиболее релевантных документа из базы знаний. Эти документы служат контекстом для генерации ответа.

**3. LLM (YandexGPT)**

В качестве языковой модели используется YandexGPT с температурой 0.5. Модель отвечает за два ключевых процесса: ведение диалога с пользователем для сбора информации о проблеме и генерацию финального ответа с указанием вероятной причины поломки и необходимых запчастей.

**4. Цепочка диалога (Conversation Chain)**

Для каждого пользователя создается отдельная цепочка с памятью ConversationBufferMemory, которая хранит историю диалога. Система использует специальный промпт, инструктирующий модель вести диалог как опытный диагност, задавая уточняющие вопросы (максимум 4 реплики) и объясняя свою логику.

**5. RAG-цепочка для генерации финального ответа**

После сбора достаточной информации происходит поиск в векторной базе с использованием RAG-системы, которая объединяет историю диалога с релевантными документами из базы знаний. Цепочка генерирует структурированный ответ в формате JSON с диагнозом и списком необходимых запчастей.

**6. Telegram Bot (интерфейс)**

Бот на базе библиотеки aiogram обеспечивает пользовательский интерфейс. Он обрабатывает текстовые сообщения и фотографии, управляет потоком диалога и отображает результаты пользователю в удобном формате.

### Взаимодействие компонентов

Процесс работы системы выглядит следующим образом:

1. Пользователь отправляет описание проблемы через Telegram-бот
2. Сообщение поступает в цепочку диалога, которая использует LLM для генерации уточняющих вопросов
3. Диалог продолжается до 4 реплик или пока модель не решит, что информации достаточно
4. По завершению диалога система извлекает релевантные документы из векторной базы через retriever
5. RAG-цепочка объединяет историю диалога и найденные документы в единый контекст
6. LLM генерирует структурированный ответ с диагнозом и списком работ в формате JSON
7. Ответ форматируется и отправляется пользователю через Telegram

### Технический стек

- **Язык программирования**: Python 3.11
- **LLM провайдер**: YandexGPT (модель yandexgpt)
- **Embeddings**: YandexGPTEmbeddings
- **Векторная БД**: FAISS
- **Фреймворк для LLM**: LangChain (langchain-community, langchain-core, langchain-classic)
- **Telegram API**: aiogram
- **Валидация данных**: Pydantic
- **Остальные зависимости**: см. requirements.txt

## 2. Реализация основной логики

### RAG-компонент

**Векторизация данных** реализована в скриптах `create_vector_db.py` и `merge_vector_db.py`. Процесс разбит на батчи по 1000 чанков для обеспечения отказоустойчивости. Каждый батч сохраняется отдельно, после чего все батчи объединяются в единую FAISS-базу.

**База данных** хранится в директории `vectorstore/db_faiss/` и содержит два файла: index.faiss (сам FAISS-индекс) и index.pkl (метаданные документов). Размер итоговой базы превышает возможности GitHub, поэтому в репозитории представлен только пример одного батча.

**Retrieval** реализован через стандартный интерфейс LangChain retriever с поиском по сходству (similarity search). Для каждого запроса возвращается 3 наиболее релевантных документа, которые передаются в промпт для генерации сметы.

### Диалоговая цепочка

Диалог организован через `ConversationChain` с промптом `SYSTEM_PROMPT_DIALOGUE`, который инструктирует модель:
- Вести себя как опытный диагност и задавать целенаправленные вопросы
- Соблюдать лимит в 4 реплики для сбора информации
- Использовать триггерную фразу для перехода к генерации финального ответа

Память диалога реализована через `ConversationBufferMemory`, которая хранит всю историю сообщений в формате HumanMessage/AIMessage. Для каждого пользователя создается отдельный экземпляр памяти.

### Генерация финального ответа

Ответ генерируется через RAG-цепочку, которая:
1. Принимает на вход историю диалога и запрос пользователя
2. Извлекает релевантные документы через retriever
3. Формирует промпт с контекстом из базы знаний и историей диалога
4. Использует JsonOutputParser с Pydantic-моделью Estimate для получения структурированного ответа
5. Возвращает JSON с полями estimated_cause и required_parts

Промпт `SYSTEM_PROMPT_ESTIMATE` явно указывает модели использовать свои знания как основу, а документы из базы — как справочный материал для проверки.

### End-to-end функциональность

Система полностью работоспособна от получения сообщения пользователя до выдачи финальной сметы. Реализованы обработка ошибок, логирование ключевых событий и корректная очистка памяти после завершения диалога.

## 3. Первичное тестирование и оценка качества

### Подготовка валидационной выборки

Для тестирования системы был подготовлен набор из 1000 вопросов, представляющих типичные проблемы с бытовой техникой. Вопросы были сохранены в файле `eval_data/dialogue_start.txt` и охватывают различные категории техники и типы неисправностей.

### Генерация тестовых диалогов

Процесс тестирования был автоматизирован с помощью скрипта `generate_dialogues.py`, который:

1. **Симулирует пользователя**: Для имитации реального пользователя используется отдельный экземпляр YandexGPT с температурой 0.7, который генерирует ответы на вопросы бота исходя из контекста диалога
2. **Генерирует диалоги**: Для каждого начального вопроса система проводит полный диалог с ботом, включая 3-4 обмена репликами
3. **Сохраняет результаты**: Каждый диалог сохраняется в CSV-файл `generated_dialogues.csv` с полной историей переписки, финальным ответом и использованными чанками из базы знаний

В результате было сгенерировано 1000 полных диалогов.

### Оценка качества (LLM-as-a-Judge)

Для объективной оценки качества диалогов был реализован подход LLM-as-a-Judge в скрипте `llm_judge.py`. Процесс оценки включает:

**Методология оценки**:
- В качестве судьи используется YandexGPT с низкой температурой (0.3) для консистентности оценок
- Каждый диалог оценивается по 11 критериям с использованием детального промпта (`eval_data/prompt_judge.txt`)
- Модель-судья получает на вход: полную историю диалога, финальный ответ бота и использованные чанки контекста
- Для каждого критерия выставляется оценка от 1 до 10 с кратким обоснованием

**Критерии оценки**:

1. **diagnostic_accuracy** — Диагностическая правдоподобность (насколько вероятна указанная причина поломки)
2. **use_of_dialogue_information** — Учет информации из диалога (использует ли ответ детали из переписки)
3. **logical_consistency** — Логичность и непротиворечивость рассуждений
4. **estimate_completeness** — Полнота предварительной оценки работ
5. **parts_and_works_adequacy** — Соответствие запчастей/работ диагнозу
6. **safety** — Безопасность рекомендаций
7. **clarity** — Ясность и понятность для пользователя
8. **actionability** — Пригодность ответа к действию
9. **uncertainty_handling** — Корректная работа с неопределенностью
10. **business_logic_alignment** — Соответствие бизнес-логике (предварительная оценка, не финальный диагноз)
11. **contextual_relevancy** — Релевантность использованных чанков из базы знаний

### Полученные метрики

Оценка проводилась на 1000 диалогах. Результаты представлены ниже:

**Метрики по критериям**:

| Критерий | Среднее | Медиана | Мин | Макс |
|----------|---------|---------|-----|------|
| diagnostic_accuracy | 7.55 | 7.00 | 1 | 10 |
| use_of_dialogue_information | 8.51 | 9.00 | 2 | 10 |
| logical_consistency | 8.58 | 9.00 | 2 | 10 |
| estimate_completeness | 6.53 | 7.00 | 1 | 10 |
| parts_and_works_adequacy | 7.34 | 8.00 | 1 | 10 |
| safety | 9.95 | 10.00 | 6 | 10 |
| clarity | 8.96 | 9.00 | 4 | 10 |
| actionability | 7.73 | 8.00 | 1 | 10 |
| uncertainty_handling | 9.75 | 10.00 | 3 | 10 |
| business_logic_alignment | 9.85 | 10.00 | 3 | 10 |
| contextual_relevancy | 4.39 | 4.00 | 1 | 10 |

**Общая средняя оценка: 8.10 / 10**

### Интерпретация результатов

**Сильные стороны системы**:
- **Безопасность** (9.95) — система не дает опасных советов и корректно позиционирует себя
- **Работа с неопределенностью** (9.75) — бот правильно использует формулировки "вероятно", "предварительно"
- **Бизнес-логика** (9.85) — четко разделяет предварительную оценку и роль мастера
- **Ясность** (8.96) — ответы понятны пользователям без технических знаний
- **Логичность** (8.58) — рассуждения последовательны и непротиворечивы
- **Учет диалога** (8.51) — система хорошо использует информацию из переписки

**Области для улучшения**:
- **Релевантность контекста** (4.39) — основная проблема системы. Retriever иногда возвращает документы, не полностью соответствующие проблеме пользователя. Это указывает на необходимость улучшения качества поиска (возможно, через reranking или гибридный поиск)
- **Полнота оценки** (6.53) — иногда ответ содержит недостаточно деталей
- **Диагностическая точность** (7.55) — хотя оценка приемлемая, есть пространство для улучшения точности диагностики

**Выводы**:

Система демонстрирует хорошее качество работы с общей оценкой 8.10/10, что является достойным результатом для baseline-решения. Бот безопасен, логичен, понятен пользователям и корректно работает с неопределенностью. 

Основным направлением для улучшения является качество RAG-компонента — необходимо повысить релевантность извлекаемого контекста. Также стоит поработать над полнотой и точностью диагностики.

Все результаты оценки сохранены в файлах `evaluated_dialogues.csv` (детальные оценки каждого диалога) и `evaluation_report.txt` (сводный отчет с метриками).